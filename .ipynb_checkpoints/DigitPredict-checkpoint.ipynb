{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3ae8049-db2b-4777-8ec9-b95decc41dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ffd6d16-972d-4bcd-822b-25915159d2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = False,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a9b2cf8-c19b-4849-940a-d608b1ec96d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loaders = {\n",
    "    'train': DataLoader(train_data,\n",
    "                        batch_size = 100,\n",
    "                        shuffle = True,\n",
    "                        num_workers = 1),\n",
    "    'test': DataLoader(test_data,\n",
    "                       batch_size = 100,\n",
    "                       shuffle = True,\n",
    "                       num_workers = 1),\n",
    "                       \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4637d1b2-04e9-4841-a5e9-fd78f68343b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x1e718fcc7c0>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x1e719abfe80>}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b26c8af-b411-4f82-95b5-c850623ceb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "#create neural network module\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1,10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10,20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    #activation functions must be called manually in forward function\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training = self.training)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return F.softmax(x)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7434e21d-f73e-4ca4-97b2-27f58eacd943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = CNN().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 20 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(loaders[\"train\"].dataset)} ({100. * batch_idx / len(loaders[\"train\"]):.0f}%)]\\t{loss.item():.6}')\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct=  0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in loaders['test']:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_fn(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(loaders['test'].dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy {correct}/{len(loaders[\"test\"].dataset)} ({100. * correct / len(loaders[\"test\"].dataset):.0f}%\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "249c1f02-eaae-4576-8f67-3512bbc8ad7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\japee\\AppData\\Local\\Temp\\ipykernel_6276\\3927722207.py:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\t2.30301\n",
      "Train Epoch: 1 [2000/60000 (3%)]\t2.29338\n",
      "Train Epoch: 1 [4000/60000 (7%)]\t2.17451\n",
      "Train Epoch: 1 [6000/60000 (10%)]\t2.00963\n",
      "Train Epoch: 1 [8000/60000 (13%)]\t1.86589\n",
      "Train Epoch: 1 [10000/60000 (17%)]\t1.73653\n",
      "Train Epoch: 1 [12000/60000 (20%)]\t1.77302\n",
      "Train Epoch: 1 [14000/60000 (23%)]\t1.7201\n",
      "Train Epoch: 1 [16000/60000 (27%)]\t1.65664\n",
      "Train Epoch: 1 [18000/60000 (30%)]\t1.6879\n",
      "Train Epoch: 1 [20000/60000 (33%)]\t1.64893\n",
      "Train Epoch: 1 [22000/60000 (37%)]\t1.64376\n",
      "Train Epoch: 1 [24000/60000 (40%)]\t1.59058\n",
      "Train Epoch: 1 [26000/60000 (43%)]\t1.72603\n",
      "Train Epoch: 1 [28000/60000 (47%)]\t1.63557\n",
      "Train Epoch: 1 [30000/60000 (50%)]\t1.66561\n",
      "Train Epoch: 1 [32000/60000 (53%)]\t1.60971\n",
      "Train Epoch: 1 [34000/60000 (57%)]\t1.61674\n",
      "Train Epoch: 1 [36000/60000 (60%)]\t1.67849\n",
      "Train Epoch: 1 [38000/60000 (63%)]\t1.63458\n",
      "Train Epoch: 1 [40000/60000 (67%)]\t1.61577\n",
      "Train Epoch: 1 [42000/60000 (70%)]\t1.61621\n",
      "Train Epoch: 1 [44000/60000 (73%)]\t1.63313\n",
      "Train Epoch: 1 [46000/60000 (77%)]\t1.57873\n",
      "Train Epoch: 1 [48000/60000 (80%)]\t1.59433\n",
      "Train Epoch: 1 [50000/60000 (83%)]\t1.5809\n",
      "Train Epoch: 1 [52000/60000 (87%)]\t1.61051\n",
      "Train Epoch: 1 [54000/60000 (90%)]\t1.6008\n",
      "Train Epoch: 1 [56000/60000 (93%)]\t1.61643\n",
      "Train Epoch: 1 [58000/60000 (97%)]\t1.59709\n",
      "\n",
      "Test set: Average loss: 0.0152, Accuracy 9384/10000 (94%\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\t1.61892\n",
      "Train Epoch: 2 [2000/60000 (3%)]\t1.55405\n",
      "Train Epoch: 2 [4000/60000 (7%)]\t1.5853\n",
      "Train Epoch: 2 [6000/60000 (10%)]\t1.63027\n",
      "Train Epoch: 2 [8000/60000 (13%)]\t1.58361\n",
      "Train Epoch: 2 [10000/60000 (17%)]\t1.56701\n",
      "Train Epoch: 2 [12000/60000 (20%)]\t1.59078\n",
      "Train Epoch: 2 [14000/60000 (23%)]\t1.55823\n",
      "Train Epoch: 2 [16000/60000 (27%)]\t1.5718\n",
      "Train Epoch: 2 [18000/60000 (30%)]\t1.53178\n",
      "Train Epoch: 2 [20000/60000 (33%)]\t1.58436\n",
      "Train Epoch: 2 [22000/60000 (37%)]\t1.6158\n",
      "Train Epoch: 2 [24000/60000 (40%)]\t1.54129\n",
      "Train Epoch: 2 [26000/60000 (43%)]\t1.54053\n",
      "Train Epoch: 2 [28000/60000 (47%)]\t1.623\n",
      "Train Epoch: 2 [30000/60000 (50%)]\t1.57995\n",
      "Train Epoch: 2 [32000/60000 (53%)]\t1.57343\n",
      "Train Epoch: 2 [34000/60000 (57%)]\t1.51204\n",
      "Train Epoch: 2 [36000/60000 (60%)]\t1.56029\n",
      "Train Epoch: 2 [38000/60000 (63%)]\t1.60996\n",
      "Train Epoch: 2 [40000/60000 (67%)]\t1.5663\n",
      "Train Epoch: 2 [42000/60000 (70%)]\t1.566\n",
      "Train Epoch: 2 [44000/60000 (73%)]\t1.51669\n",
      "Train Epoch: 2 [46000/60000 (77%)]\t1.5735\n",
      "Train Epoch: 2 [48000/60000 (80%)]\t1.56188\n",
      "Train Epoch: 2 [50000/60000 (83%)]\t1.54002\n",
      "Train Epoch: 2 [52000/60000 (87%)]\t1.54469\n",
      "Train Epoch: 2 [54000/60000 (90%)]\t1.53648\n",
      "Train Epoch: 2 [56000/60000 (93%)]\t1.57977\n",
      "Train Epoch: 2 [58000/60000 (97%)]\t1.61507\n",
      "\n",
      "Test set: Average loss: 0.0151, Accuracy 9537/10000 (95%\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\t1.52266\n",
      "Train Epoch: 3 [2000/60000 (3%)]\t1.54897\n",
      "Train Epoch: 3 [4000/60000 (7%)]\t1.52135\n",
      "Train Epoch: 3 [6000/60000 (10%)]\t1.52602\n",
      "Train Epoch: 3 [8000/60000 (13%)]\t1.5303\n",
      "Train Epoch: 3 [10000/60000 (17%)]\t1.55607\n",
      "Train Epoch: 3 [12000/60000 (20%)]\t1.60612\n",
      "Train Epoch: 3 [14000/60000 (23%)]\t1.5599\n",
      "Train Epoch: 3 [16000/60000 (27%)]\t1.56746\n",
      "Train Epoch: 3 [18000/60000 (30%)]\t1.52613\n",
      "Train Epoch: 3 [20000/60000 (33%)]\t1.52585\n",
      "Train Epoch: 3 [22000/60000 (37%)]\t1.55839\n",
      "Train Epoch: 3 [24000/60000 (40%)]\t1.55025\n",
      "Train Epoch: 3 [26000/60000 (43%)]\t1.53259\n",
      "Train Epoch: 3 [28000/60000 (47%)]\t1.55747\n",
      "Train Epoch: 3 [30000/60000 (50%)]\t1.55723\n",
      "Train Epoch: 3 [32000/60000 (53%)]\t1.60284\n",
      "Train Epoch: 3 [34000/60000 (57%)]\t1.57771\n",
      "Train Epoch: 3 [36000/60000 (60%)]\t1.5609\n",
      "Train Epoch: 3 [38000/60000 (63%)]\t1.56749\n",
      "Train Epoch: 3 [40000/60000 (67%)]\t1.60001\n",
      "Train Epoch: 3 [42000/60000 (70%)]\t1.51665\n",
      "Train Epoch: 3 [44000/60000 (73%)]\t1.55609\n",
      "Train Epoch: 3 [46000/60000 (77%)]\t1.56013\n",
      "Train Epoch: 3 [48000/60000 (80%)]\t1.54332\n",
      "Train Epoch: 3 [50000/60000 (83%)]\t1.53418\n",
      "Train Epoch: 3 [52000/60000 (87%)]\t1.57682\n",
      "Train Epoch: 3 [54000/60000 (90%)]\t1.5665\n",
      "Train Epoch: 3 [56000/60000 (93%)]\t1.52665\n",
      "Train Epoch: 3 [58000/60000 (97%)]\t1.57575\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy 9604/10000 (96%\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\t1.58158\n",
      "Train Epoch: 4 [2000/60000 (3%)]\t1.53452\n",
      "Train Epoch: 4 [4000/60000 (7%)]\t1.53283\n",
      "Train Epoch: 4 [6000/60000 (10%)]\t1.54353\n",
      "Train Epoch: 4 [8000/60000 (13%)]\t1.52285\n",
      "Train Epoch: 4 [10000/60000 (17%)]\t1.55677\n",
      "Train Epoch: 4 [12000/60000 (20%)]\t1.57318\n",
      "Train Epoch: 4 [14000/60000 (23%)]\t1.54262\n",
      "Train Epoch: 4 [16000/60000 (27%)]\t1.56607\n",
      "Train Epoch: 4 [18000/60000 (30%)]\t1.52018\n",
      "Train Epoch: 4 [20000/60000 (33%)]\t1.6014\n",
      "Train Epoch: 4 [22000/60000 (37%)]\t1.53507\n",
      "Train Epoch: 4 [24000/60000 (40%)]\t1.52128\n",
      "Train Epoch: 4 [26000/60000 (43%)]\t1.52116\n",
      "Train Epoch: 4 [28000/60000 (47%)]\t1.52521\n",
      "Train Epoch: 4 [30000/60000 (50%)]\t1.53982\n",
      "Train Epoch: 4 [32000/60000 (53%)]\t1.51584\n",
      "Train Epoch: 4 [34000/60000 (57%)]\t1.57226\n",
      "Train Epoch: 4 [36000/60000 (60%)]\t1.49746\n",
      "Train Epoch: 4 [38000/60000 (63%)]\t1.52125\n",
      "Train Epoch: 4 [40000/60000 (67%)]\t1.52192\n",
      "Train Epoch: 4 [42000/60000 (70%)]\t1.55963\n",
      "Train Epoch: 4 [44000/60000 (73%)]\t1.53085\n",
      "Train Epoch: 4 [46000/60000 (77%)]\t1.55065\n",
      "Train Epoch: 4 [48000/60000 (80%)]\t1.56941\n",
      "Train Epoch: 4 [50000/60000 (83%)]\t1.51602\n",
      "Train Epoch: 4 [52000/60000 (87%)]\t1.51478\n",
      "Train Epoch: 4 [54000/60000 (90%)]\t1.52617\n",
      "Train Epoch: 4 [56000/60000 (93%)]\t1.61372\n",
      "Train Epoch: 4 [58000/60000 (97%)]\t1.52636\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy 9613/10000 (96%\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\t1.56467\n",
      "Train Epoch: 5 [2000/60000 (3%)]\t1.51552\n",
      "Train Epoch: 5 [4000/60000 (7%)]\t1.51262\n",
      "Train Epoch: 5 [6000/60000 (10%)]\t1.51821\n",
      "Train Epoch: 5 [8000/60000 (13%)]\t1.57162\n",
      "Train Epoch: 5 [10000/60000 (17%)]\t1.54065\n",
      "Train Epoch: 5 [12000/60000 (20%)]\t1.56611\n",
      "Train Epoch: 5 [14000/60000 (23%)]\t1.55484\n",
      "Train Epoch: 5 [16000/60000 (27%)]\t1.54279\n",
      "Train Epoch: 5 [18000/60000 (30%)]\t1.52465\n",
      "Train Epoch: 5 [20000/60000 (33%)]\t1.51805\n",
      "Train Epoch: 5 [22000/60000 (37%)]\t1.50254\n",
      "Train Epoch: 5 [24000/60000 (40%)]\t1.53114\n",
      "Train Epoch: 5 [26000/60000 (43%)]\t1.53849\n",
      "Train Epoch: 5 [28000/60000 (47%)]\t1.57607\n",
      "Train Epoch: 5 [30000/60000 (50%)]\t1.53522\n",
      "Train Epoch: 5 [32000/60000 (53%)]\t1.50764\n",
      "Train Epoch: 5 [34000/60000 (57%)]\t1.53519\n",
      "Train Epoch: 5 [36000/60000 (60%)]\t1.51945\n",
      "Train Epoch: 5 [38000/60000 (63%)]\t1.58224\n",
      "Train Epoch: 5 [40000/60000 (67%)]\t1.54702\n",
      "Train Epoch: 5 [42000/60000 (70%)]\t1.55014\n",
      "Train Epoch: 5 [44000/60000 (73%)]\t1.55164\n",
      "Train Epoch: 5 [46000/60000 (77%)]\t1.53258\n",
      "Train Epoch: 5 [48000/60000 (80%)]\t1.54599\n",
      "Train Epoch: 5 [50000/60000 (83%)]\t1.50854\n",
      "Train Epoch: 5 [52000/60000 (87%)]\t1.52273\n",
      "Train Epoch: 5 [54000/60000 (90%)]\t1.52462\n",
      "Train Epoch: 5 [56000/60000 (93%)]\t1.51576\n",
      "Train Epoch: 5 [58000/60000 (97%)]\t1.5199\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy 9664/10000 (97%\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\t1.5619\n",
      "Train Epoch: 6 [2000/60000 (3%)]\t1.53385\n",
      "Train Epoch: 6 [4000/60000 (7%)]\t1.53144\n",
      "Train Epoch: 6 [6000/60000 (10%)]\t1.53488\n",
      "Train Epoch: 6 [8000/60000 (13%)]\t1.50893\n",
      "Train Epoch: 6 [10000/60000 (17%)]\t1.52239\n",
      "Train Epoch: 6 [12000/60000 (20%)]\t1.56523\n",
      "Train Epoch: 6 [14000/60000 (23%)]\t1.54602\n",
      "Train Epoch: 6 [16000/60000 (27%)]\t1.55186\n",
      "Train Epoch: 6 [18000/60000 (30%)]\t1.56167\n",
      "Train Epoch: 6 [20000/60000 (33%)]\t1.53918\n",
      "Train Epoch: 6 [22000/60000 (37%)]\t1.52866\n",
      "Train Epoch: 6 [24000/60000 (40%)]\t1.52636\n",
      "Train Epoch: 6 [26000/60000 (43%)]\t1.50927\n",
      "Train Epoch: 6 [28000/60000 (47%)]\t1.52425\n",
      "Train Epoch: 6 [30000/60000 (50%)]\t1.56948\n",
      "Train Epoch: 6 [32000/60000 (53%)]\t1.55278\n",
      "Train Epoch: 6 [34000/60000 (57%)]\t1.51786\n",
      "Train Epoch: 6 [36000/60000 (60%)]\t1.56785\n",
      "Train Epoch: 6 [38000/60000 (63%)]\t1.53675\n",
      "Train Epoch: 6 [40000/60000 (67%)]\t1.53631\n",
      "Train Epoch: 6 [42000/60000 (70%)]\t1.57509\n",
      "Train Epoch: 6 [44000/60000 (73%)]\t1.54538\n",
      "Train Epoch: 6 [46000/60000 (77%)]\t1.5147\n",
      "Train Epoch: 6 [48000/60000 (80%)]\t1.5146\n",
      "Train Epoch: 6 [50000/60000 (83%)]\t1.54926\n",
      "Train Epoch: 6 [52000/60000 (87%)]\t1.53212\n",
      "Train Epoch: 6 [54000/60000 (90%)]\t1.57014\n",
      "Train Epoch: 6 [56000/60000 (93%)]\t1.52895\n",
      "Train Epoch: 6 [58000/60000 (97%)]\t1.56549\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy 9686/10000 (97%\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\t1.5092\n",
      "Train Epoch: 7 [2000/60000 (3%)]\t1.5069\n",
      "Train Epoch: 7 [4000/60000 (7%)]\t1.52729\n",
      "Train Epoch: 7 [6000/60000 (10%)]\t1.54195\n",
      "Train Epoch: 7 [8000/60000 (13%)]\t1.53774\n",
      "Train Epoch: 7 [10000/60000 (17%)]\t1.5515\n",
      "Train Epoch: 7 [12000/60000 (20%)]\t1.51315\n",
      "Train Epoch: 7 [14000/60000 (23%)]\t1.51785\n",
      "Train Epoch: 7 [16000/60000 (27%)]\t1.5488\n",
      "Train Epoch: 7 [18000/60000 (30%)]\t1.55111\n",
      "Train Epoch: 7 [20000/60000 (33%)]\t1.52001\n",
      "Train Epoch: 7 [22000/60000 (37%)]\t1.50449\n",
      "Train Epoch: 7 [24000/60000 (40%)]\t1.54802\n",
      "Train Epoch: 7 [26000/60000 (43%)]\t1.5648\n",
      "Train Epoch: 7 [28000/60000 (47%)]\t1.52172\n",
      "Train Epoch: 7 [30000/60000 (50%)]\t1.5468\n",
      "Train Epoch: 7 [32000/60000 (53%)]\t1.53885\n",
      "Train Epoch: 7 [34000/60000 (57%)]\t1.53773\n",
      "Train Epoch: 7 [36000/60000 (60%)]\t1.51651\n",
      "Train Epoch: 7 [38000/60000 (63%)]\t1.5183\n",
      "Train Epoch: 7 [40000/60000 (67%)]\t1.52972\n",
      "Train Epoch: 7 [42000/60000 (70%)]\t1.53165\n",
      "Train Epoch: 7 [44000/60000 (73%)]\t1.53926\n",
      "Train Epoch: 7 [46000/60000 (77%)]\t1.55859\n",
      "Train Epoch: 7 [48000/60000 (80%)]\t1.56615\n",
      "Train Epoch: 7 [50000/60000 (83%)]\t1.55175\n",
      "Train Epoch: 7 [52000/60000 (87%)]\t1.52499\n",
      "Train Epoch: 7 [54000/60000 (90%)]\t1.50888\n",
      "Train Epoch: 7 [56000/60000 (93%)]\t1.55253\n",
      "Train Epoch: 7 [58000/60000 (97%)]\t1.51117\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy 9719/10000 (97%\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\t1.52958\n",
      "Train Epoch: 8 [2000/60000 (3%)]\t1.53151\n",
      "Train Epoch: 8 [4000/60000 (7%)]\t1.49742\n",
      "Train Epoch: 8 [6000/60000 (10%)]\t1.50317\n",
      "Train Epoch: 8 [8000/60000 (13%)]\t1.53156\n",
      "Train Epoch: 8 [10000/60000 (17%)]\t1.56047\n",
      "Train Epoch: 8 [12000/60000 (20%)]\t1.55467\n",
      "Train Epoch: 8 [14000/60000 (23%)]\t1.51257\n",
      "Train Epoch: 8 [16000/60000 (27%)]\t1.52425\n",
      "Train Epoch: 8 [18000/60000 (30%)]\t1.53427\n",
      "Train Epoch: 8 [20000/60000 (33%)]\t1.50377\n",
      "Train Epoch: 8 [22000/60000 (37%)]\t1.51397\n",
      "Train Epoch: 8 [24000/60000 (40%)]\t1.50196\n",
      "Train Epoch: 8 [26000/60000 (43%)]\t1.52728\n",
      "Train Epoch: 8 [28000/60000 (47%)]\t1.52807\n",
      "Train Epoch: 8 [30000/60000 (50%)]\t1.50596\n",
      "Train Epoch: 8 [32000/60000 (53%)]\t1.52159\n",
      "Train Epoch: 8 [34000/60000 (57%)]\t1.52343\n",
      "Train Epoch: 8 [36000/60000 (60%)]\t1.51649\n",
      "Train Epoch: 8 [38000/60000 (63%)]\t1.50364\n",
      "Train Epoch: 8 [40000/60000 (67%)]\t1.5496\n",
      "Train Epoch: 8 [42000/60000 (70%)]\t1.54366\n",
      "Train Epoch: 8 [44000/60000 (73%)]\t1.52539\n",
      "Train Epoch: 8 [46000/60000 (77%)]\t1.53827\n",
      "Train Epoch: 8 [48000/60000 (80%)]\t1.52383\n",
      "Train Epoch: 8 [50000/60000 (83%)]\t1.5525\n",
      "Train Epoch: 8 [52000/60000 (87%)]\t1.51288\n",
      "Train Epoch: 8 [54000/60000 (90%)]\t1.57181\n",
      "Train Epoch: 8 [56000/60000 (93%)]\t1.5296\n",
      "Train Epoch: 8 [58000/60000 (97%)]\t1.55307\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy 9739/10000 (97%\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\t1.51922\n",
      "Train Epoch: 9 [2000/60000 (3%)]\t1.51856\n",
      "Train Epoch: 9 [4000/60000 (7%)]\t1.52064\n",
      "Train Epoch: 9 [6000/60000 (10%)]\t1.51643\n",
      "Train Epoch: 9 [8000/60000 (13%)]\t1.54911\n",
      "Train Epoch: 9 [10000/60000 (17%)]\t1.56079\n",
      "Train Epoch: 9 [12000/60000 (20%)]\t1.47447\n",
      "Train Epoch: 9 [14000/60000 (23%)]\t1.52167\n",
      "Train Epoch: 9 [16000/60000 (27%)]\t1.51641\n",
      "Train Epoch: 9 [18000/60000 (30%)]\t1.49307\n",
      "Train Epoch: 9 [20000/60000 (33%)]\t1.49612\n",
      "Train Epoch: 9 [22000/60000 (37%)]\t1.48594\n",
      "Train Epoch: 9 [24000/60000 (40%)]\t1.54131\n",
      "Train Epoch: 9 [26000/60000 (43%)]\t1.52759\n",
      "Train Epoch: 9 [28000/60000 (47%)]\t1.51612\n",
      "Train Epoch: 9 [30000/60000 (50%)]\t1.50569\n",
      "Train Epoch: 9 [32000/60000 (53%)]\t1.51849\n",
      "Train Epoch: 9 [34000/60000 (57%)]\t1.47106\n",
      "Train Epoch: 9 [36000/60000 (60%)]\t1.54725\n",
      "Train Epoch: 9 [38000/60000 (63%)]\t1.5199\n",
      "Train Epoch: 9 [40000/60000 (67%)]\t1.56555\n",
      "Train Epoch: 9 [42000/60000 (70%)]\t1.48484\n",
      "Train Epoch: 9 [44000/60000 (73%)]\t1.52223\n",
      "Train Epoch: 9 [46000/60000 (77%)]\t1.50362\n",
      "Train Epoch: 9 [48000/60000 (80%)]\t1.52812\n",
      "Train Epoch: 9 [50000/60000 (83%)]\t1.52425\n",
      "Train Epoch: 9 [52000/60000 (87%)]\t1.522\n",
      "Train Epoch: 9 [54000/60000 (90%)]\t1.50012\n",
      "Train Epoch: 9 [56000/60000 (93%)]\t1.50298\n",
      "Train Epoch: 9 [58000/60000 (97%)]\t1.50678\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy 9756/10000 (98%\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\t1.53424\n",
      "Train Epoch: 10 [2000/60000 (3%)]\t1.51405\n",
      "Train Epoch: 10 [4000/60000 (7%)]\t1.56618\n",
      "Train Epoch: 10 [6000/60000 (10%)]\t1.49644\n",
      "Train Epoch: 10 [8000/60000 (13%)]\t1.52934\n",
      "Train Epoch: 10 [10000/60000 (17%)]\t1.52583\n",
      "Train Epoch: 10 [12000/60000 (20%)]\t1.54062\n",
      "Train Epoch: 10 [14000/60000 (23%)]\t1.52895\n",
      "Train Epoch: 10 [16000/60000 (27%)]\t1.52845\n",
      "Train Epoch: 10 [18000/60000 (30%)]\t1.50079\n",
      "Train Epoch: 10 [20000/60000 (33%)]\t1.51213\n",
      "Train Epoch: 10 [22000/60000 (37%)]\t1.50711\n",
      "Train Epoch: 10 [24000/60000 (40%)]\t1.49856\n",
      "Train Epoch: 10 [26000/60000 (43%)]\t1.53737\n",
      "Train Epoch: 10 [28000/60000 (47%)]\t1.56866\n",
      "Train Epoch: 10 [30000/60000 (50%)]\t1.50683\n",
      "Train Epoch: 10 [32000/60000 (53%)]\t1.55081\n",
      "Train Epoch: 10 [34000/60000 (57%)]\t1.52354\n",
      "Train Epoch: 10 [36000/60000 (60%)]\t1.51332\n",
      "Train Epoch: 10 [38000/60000 (63%)]\t1.52676\n",
      "Train Epoch: 10 [40000/60000 (67%)]\t1.5415\n",
      "Train Epoch: 10 [42000/60000 (70%)]\t1.52354\n",
      "Train Epoch: 10 [44000/60000 (73%)]\t1.49516\n",
      "Train Epoch: 10 [46000/60000 (77%)]\t1.51617\n",
      "Train Epoch: 10 [48000/60000 (80%)]\t1.4986\n",
      "Train Epoch: 10 [50000/60000 (83%)]\t1.52356\n",
      "Train Epoch: 10 [52000/60000 (87%)]\t1.48231\n",
      "Train Epoch: 10 [54000/60000 (90%)]\t1.52904\n",
      "Train Epoch: 10 [56000/60000 (93%)]\t1.54164\n",
      "Train Epoch: 10 [58000/60000 (97%)]\t1.5092\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy 9761/10000 (98%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#start training\n",
    "#10 epochs\n",
    "for epoch in range(1, 11):\n",
    "    train(epoch)\n",
    "    test()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "63daaf77-d659-4e7c-8cb8-e9e604e72f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n",
      "tensor([[1.0000e+00, 9.7102e-30, 4.1290e-14, 7.1678e-20, 1.2386e-30, 3.2347e-21,\n",
      "         5.2726e-21, 1.9776e-17, 7.0661e-18, 2.0664e-22]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Prediction: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\japee\\AppData\\Local\\Temp\\ipykernel_6276\\3927722207.py:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAb4klEQVR4nO3de3BU5f3H8U/CZUVJloaYbFYCJqDgiNARJaYoxBIT0g4Fpd7qH+A4OGBwKlTtpKOivaWi01pbiv2jQ2oLeJkKKLV0IJJgS4JDlGGoNUOYtAlDEioz2YVgApLn9wfj/lwJl7Ps5pvL+zXzzCTnnG+eL8djPjm7J0+SnHNOAAD0smTrBgAAgxMBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABNDrRv4qu7ubh0+fFgpKSlKSkqybgcA4JFzTseOHVMwGFRy8rnvc/pcAB0+fFjZ2dnWbQAALlFzc7PGjBlzzv197iW4lJQU6xYAAHFwoe/nCQug1atX6+qrr9Zll12mvLw8ffDBBxdVx8tuADAwXOj7eUIC6PXXX9eKFSu0cuVKffjhh5o6daqKi4t15MiRREwHAOiPXAJMnz7dlZaWRj4/ffq0CwaDrry8/IK1oVDISWIwGAxGPx+hUOi83+/jfgd08uRJ1dXVqbCwMLItOTlZhYWFqqmpOev4rq4uhcPhqAEAGPjiHkCffvqpTp8+rczMzKjtmZmZam1tPev48vJy+f3+yOAJOAAYHMyfgisrK1MoFIqM5uZm65YAAL0g7r8HlJ6eriFDhqitrS1qe1tbmwKBwFnH+3w++Xy+eLcBAOjj4n4HNHz4cE2bNk2VlZWRbd3d3aqsrFR+fn68pwMA9FMJWQlhxYoVWrhwoW666SZNnz5dL730kjo6OvTggw8mYjoAQD+UkAC699579b///U/PPPOMWltb9fWvf11bt24968EEAMDgleScc9ZNfFk4HJbf77duAwBwiUKhkFJTU8+53/wpOADA4EQAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADAxFDrBoDBqKCgwHNNWVmZ55o77rjDc40k/eIXv/BcU1dX57nmL3/5i+caDBzcAQEATBBAAAATcQ+gZ599VklJSVFj0qRJ8Z4GANDPJeQ9oOuvv17bt2///0mG8lYTACBaQpJh6NChCgQCifjSAIABIiHvAR04cEDBYFC5ubl64IEH1NTUdM5ju7q6FA6HowYAYOCLewDl5eWpoqJCW7du1Zo1a9TY2KjbbrtNx44d6/H48vJy+f3+yMjOzo53SwCAPijuAVRSUqK7775bU6ZMUXFxsd599121t7frjTfe6PH4srIyhUKhyGhubo53SwCAPijhTweMGjVK1157rRoaGnrc7/P55PP5Et0GAKCPSfjvAR0/flwHDx5UVlZWoqcCAPQjcQ+gxx9/XNXV1frPf/6jXbt26c4779SQIUN0//33x3sqAEA/FveX4A4dOqT7779fR48e1ZVXXqlbb71VtbW1uvLKK+M9FQCgH0tyzjnrJr4sHA7L7/dbtzGoxHp3+sorr8S5k54dOnTIc83Pf/7zmOZat26d55qUlBTPNUeOHPFcs3//fs81NTU1nmskadGiRZ5rYnkv91//+pfnmu985zuea2K5hnDpQqGQUlNTz7mfteAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYYDFS6OOPP46pbuLEiZ5r3n333Zjm8qqoqCimugceeMBzzeeff+65ZsSIEZ5r/vrXv3quCYfDnmskKTMz03PNr3/9a881d999t+eaVatWea5Zs2aN5xpJampqiqkOZ7AYKQCgTyKAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmBhq3QDi62c/+5nnmvHjx8c01/bt2z3X3HPPPZ5rrrrqKs81O3bs8FwjxbZK9Z/+9KeY5urL2traPNcsXrzYc013d7fnmieffNJzTX5+vucaSSooKIipDheHOyAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmkpxzzrqJLwuHw/L7/dZt9FuhUMhzzciRI2Oaq6ioyHNNZWVlTHN5NWHChJjq8vLyPNesW7cuprkgpaameq7Ztm2b55rMzEzPNVJsi5i2tLTENNdAFAqFzvvfmDsgAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJoZaNwB7sSzuKEm1tbVx7iR+GhoaerUOsQmHw55rPv74Y881N910k+caSdqwYYPnmoKCgpjmGoy4AwIAmCCAAAAmPAfQzp07NXfuXAWDQSUlJWnTpk1R+51zeuaZZ5SVlaURI0aosLBQBw4ciFe/AIABwnMAdXR0aOrUqVq9enWP+1etWqWXX35Zr7zyinbv3q0rrrhCxcXF6uzsvORmAQADh+eHEEpKSlRSUtLjPuecXnrpJT311FOaN2+eJOnVV19VZmamNm3apPvuu+/SugUADBhxfQ+osbFRra2tKiwsjGzz+/3Ky8tTTU1NjzVdXV0Kh8NRAwAw8MU1gFpbWyWd/ffXMzMzI/u+qry8XH6/PzKys7Pj2RIAoI8yfwqurKxMoVAoMpqbm61bAgD0grgGUCAQkCS1tbVFbW9ra4vs+yqfz6fU1NSoAQAY+OIaQDk5OQoEAqqsrIxsC4fD2r17t/Lz8+M5FQCgn/P8FNzx48ejlitpbGzU3r17lZaWprFjx+qxxx7TT3/6U11zzTXKycnR008/rWAwqPnz58ezbwBAP+c5gPbs2aPbb7898vmKFSskSQsXLlRFRYWefPJJdXR06OGHH1Z7e7tuvfVWbd26VZdddln8ugYA9HtJzjln3cSXhcNh+f1+6zb6rVAo5LnmrbfeimmuBx98MKY64FJMmTLFc837778f01xDh3pfr/m73/2u55q//e1vnmv6g1AodN739c2fggMADE4EEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABPel3oFAEP79u3zXPPlP5Lpxbx58zzX5ObmxjTXYMQdEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMsRgpgwOvq6rJuAT3gDggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJFiMFMODt3r07prp77rknzp3gy7gDAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYILFSAeYpKQkzzULFy6Maa7nn3/ec80nn3wS01zApZg1a1ZMdR0dHZ5r6urqYpprMOIOCABgggACAJjwHEA7d+7U3LlzFQwGlZSUpE2bNkXtX7RokZKSkqLGnDlz4tUvAGCA8BxAHR0dmjp1qlavXn3OY+bMmaOWlpbI2LBhwyU1CQAYeDw/hFBSUqKSkpLzHuPz+RQIBGJuCgAw8CXkPaCqqiplZGRo4sSJWrp0qY4ePXrOY7u6uhQOh6MGAGDgi3sAzZkzR6+++qoqKyv1/PPPq7q6WiUlJTp9+nSPx5eXl8vv90dGdnZ2vFsCAPRBcf89oPvuuy/y8Q033KApU6Zo/Pjxqqqq0uzZs886vqysTCtWrIh8Hg6HCSEAGAQS/hh2bm6u0tPT1dDQ0ON+n8+n1NTUqAEAGPgSHkCHDh3S0aNHlZWVleipAAD9iOeX4I4fPx51N9PY2Ki9e/cqLS1NaWlpeu6557RgwQIFAgEdPHhQTz75pCZMmKDi4uK4Ng4A6N88B9CePXt0++23Rz7/4v2bhQsXas2aNdq3b5/++Mc/qr29XcFgUEVFRfrJT34in88Xv64BAP2e5wAqKCiQc+6c+//+979fUkO4NLt27fJcc8cdd8Q01y233OK5hsVIYeF837POp7293XNNbW1tTHMNRqwFBwAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwEfc/yQ1bL774oueaGTNmxDTX3LlzPddUVFTENBfwhfT0dM812dnZCegEl4o7IACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACZYjHSA2b59u+eaXbt2xTRXYWGh55rJkyd7rtm/f7/nGgxcubm5nmtuvPHGmObatm1bTHW4ONwBAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMMFipNC6detiqmMxUlh45JFHem2uWP/fwMXhDggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJFiOFtm3bFlPdrl27PNf89re/9Vxz4sQJzzVvv/225xr0Pr/f77nmuuuu81zT2dnpuUaSPv3005jqcHG4AwIAmCCAAAAmPAVQeXm5br75ZqWkpCgjI0Pz589XfX191DGdnZ0qLS3V6NGjNXLkSC1YsEBtbW1xbRoA0P95CqDq6mqVlpaqtrZW27Zt06lTp1RUVKSOjo7IMcuXL9c777yjN998U9XV1Tp8+LDuuuuuuDcOAOjfPD2EsHXr1qjPKyoqlJGRobq6Os2cOVOhUEh/+MMftH79en3zm9+UJK1du1bXXXedamtrdcstt8SvcwBAv3ZJ7wGFQiFJUlpamiSprq5Op06divpTzZMmTdLYsWNVU1PT49fo6upSOByOGgCAgS/mAOru7tZjjz2mGTNmaPLkyZKk1tZWDR8+XKNGjYo6NjMzU62trT1+nfLycvn9/sjIzs6OtSUAQD8ScwCVlpZq//79eu211y6pgbKyMoVCochobm6+pK8HAOgfYvpF1GXLlmnLli3auXOnxowZE9keCAR08uRJtbe3R90FtbW1KRAI9Pi1fD6ffD5fLG0AAPoxT3dAzjktW7ZMGzdu1HvvvaecnJyo/dOmTdOwYcNUWVkZ2VZfX6+mpibl5+fHp2MAwIDg6Q6otLRU69ev1+bNm5WSkhJ5X8fv92vEiBHy+/166KGHtGLFCqWlpSk1NVWPPvqo8vPzeQIOABDFUwCtWbNGklRQUBC1fe3atVq0aJEk6Ve/+pWSk5O1YMECdXV1qbi4WL/73e/i0iwAYOBIcs456ya+LBwOx7RAIXpfMBj0XLNjxw7PNaNHj/Zc88UPRF5t2bIlpjooplc5XnjhBc813/jGNzzXvP/++55rpLN/2IY3oVBIqamp59zPWnAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABOsho1eVVJS4rnmqaee8lxz3XXXea6RpHfeecdzzdtvv+25pra21nNNb7rxxhs91yxfvtxzzaxZszzXPP/8855rvvhTMl41NzfHVIczWA0bANAnEUAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMMFipOjzMjMzPdcsXbo0prliWVBz5MiRMc3lVXKy958Xu7u7E9BJzz7//HPPNS+++KLnmlgWFj106JDnGlw6FiMFAPRJBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATLAYKfAlKSkpnmtKS0sT0MnZZs2a5bmmpqYmprlOnjzpuaa+vt5zzcaNGz3XoP9gMVIAQJ9EAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABIuRAgASgsVIAQB9EgEEADDhKYDKy8t18803KyUlRRkZGZo/f/5ZfwOkoKBASUlJUWPJkiVxbRoA0P95CqDq6mqVlpaqtrZW27Zt06lTp1RUVKSOjo6o4xYvXqyWlpbIWLVqVVybBgD0f0O9HLx169aozysqKpSRkaG6ujrNnDkzsv3yyy9XIBCIT4cAgAHpkt4DCoVCkqS0tLSo7evWrVN6eromT56ssrIynThx4pxfo6urS+FwOGoAAAYBF6PTp0+7b3/7227GjBlR23//+9+7rVu3un379rk///nP7qqrrnJ33nnnOb/OypUrnSQGg8FgDLARCoXOmyMxB9CSJUvcuHHjXHNz83mPq6ysdJJcQ0NDj/s7OztdKBSKjObmZvOTxmAwGIxLHxcKIE/vAX1h2bJl2rJli3bu3KkxY8ac99i8vDxJUkNDg8aPH3/Wfp/PJ5/PF0sbAIB+zFMAOef06KOPauPGjaqqqlJOTs4Fa/bu3StJysrKiqlBAMDA5CmASktLtX79em3evFkpKSlqbW2VJPn9fo0YMUIHDx7U+vXr9a1vfUujR4/Wvn37tHz5cs2cOVNTpkxJyD8AANBPeXnfR+d4nW/t2rXOOeeamprczJkzXVpamvP5fG7ChAnuiSeeuODrgF8WCoXMX7dkMBgMxqWPC33vZzFSAEBCsBgpAKBPIoAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCY6HMB5JyzbgEAEAcX+n7e5wLo2LFj1i0AAOLgQt/Pk1wfu+Xo7u7W4cOHlZKSoqSkpKh94XBY2dnZam5uVmpqqlGH9jgPZ3AezuA8nMF5OKMvnAfnnI4dO6ZgMKjk5HPf5wztxZ4uSnJyssaMGXPeY1JTUwf1BfYFzsMZnIczOA9ncB7OsD4Pfr//gsf0uZfgAACDAwEEADDRrwLI5/Np5cqV8vl81q2Y4jycwXk4g/NwBufhjP50HvrcQwgAgMGhX90BAQAGDgIIAGCCAAIAmCCAAAAm+k0ArV69WldffbUuu+wy5eXl6YMPPrBuqdc9++yzSkpKihqTJk2ybivhdu7cqblz5yoYDCopKUmbNm2K2u+c0zPPPKOsrCyNGDFChYWFOnDggE2zCXSh87Bo0aKzro85c+bYNJsg5eXluvnmm5WSkqKMjAzNnz9f9fX1Ucd0dnaqtLRUo0eP1siRI7VgwQK1tbUZdZwYF3MeCgoKzroelixZYtRxz/pFAL3++utasWKFVq5cqQ8//FBTp05VcXGxjhw5Yt1ar7v++uvV0tISGf/4xz+sW0q4jo4OTZ06VatXr+5x/6pVq/Tyyy/rlVde0e7du3XFFVeouLhYnZ2dvdxpYl3oPEjSnDlzoq6PDRs29GKHiVddXa3S0lLV1tZq27ZtOnXqlIqKitTR0RE5Zvny5XrnnXf05ptvqrq6WocPH9Zdd91l2HX8Xcx5kKTFixdHXQ+rVq0y6vgcXD8wffp0V1paGvn89OnTLhgMuvLycsOuet/KlSvd1KlTrdswJclt3Lgx8nl3d7cLBALuhRdeiGxrb293Pp/PbdiwwaDD3vHV8+CccwsXLnTz5s0z6cfKkSNHnCRXXV3tnDvz337YsGHuzTffjBzz73//20lyNTU1Vm0m3FfPg3POzZo1y33/+9+3a+oi9Pk7oJMnT6qurk6FhYWRbcnJySosLFRNTY1hZzYOHDigYDCo3NxcPfDAA2pqarJuyVRjY6NaW1ujrg+/36+8vLxBeX1UVVUpIyNDEydO1NKlS3X06FHrlhIqFApJktLS0iRJdXV1OnXqVNT1MGnSJI0dO3ZAXw9fPQ9fWLdundLT0zV58mSVlZXpxIkTFu2dU59bjPSrPv30U50+fVqZmZlR2zMzM/XJJ58YdWUjLy9PFRUVmjhxolpaWvTcc8/ptttu0/79+5WSkmLdnonW1lZJ6vH6+GLfYDFnzhzdddddysnJ0cGDB/WjH/1IJSUlqqmp0ZAhQ6zbi7vu7m499thjmjFjhiZPnizpzPUwfPhwjRo1KurYgXw99HQeJOl73/uexo0bp2AwqH379umHP/yh6uvr9dZbbxl2G63PBxD+X0lJSeTjKVOmKC8vT+PGjdMbb7yhhx56yLAz9AX33Xdf5OMbbrhBU6ZM0fjx41VVVaXZs2cbdpYYpaWl2r9//6B4H/R8znUeHn744cjHN9xwg7KysjR79mwdPHhQ48eP7+02e9TnX4JLT0/XkCFDznqKpa2tTYFAwKirvmHUqFG69tpr1dDQYN2KmS+uAa6Ps+Xm5io9PX1AXh/Lli3Tli1btGPHjqg/3xIIBHTy5Em1t7dHHT9Qr4dznYee5OXlSVKfuh76fAANHz5c06ZNU2VlZWRbd3e3KisrlZ+fb9iZvePHj+vgwYPKysqybsVMTk6OAoFA1PURDoe1e/fuQX99HDp0SEePHh1Q14dzTsuWLdPGjRv13nvvKScnJ2r/tGnTNGzYsKjrob6+Xk1NTQPqerjQeejJ3r17JalvXQ/WT0FcjNdee835fD5XUVHhPv74Y/fwww+7UaNGudbWVuvWetUPfvADV1VV5RobG90///lPV1hY6NLT092RI0esW0uoY8eOuY8++sh99NFHTpL75S9/6T766CP33//+1znn3C9+8Qs3atQot3nzZrdv3z43b948l5OT4z777DPjzuPrfOfh2LFj7vHHH3c1NTWusbHRbd++3d14443ummuucZ2dndatx83SpUud3+93VVVVrqWlJTJOnDgROWbJkiVu7Nix7r333nN79uxx+fn5Lj8/37Dr+LvQeWhoaHA//vGP3Z49e1xjY6PbvHmzy83NdTNnzjTuPFq/CCDnnPvNb37jxo4d64YPH+6mT5/uamtrrVvqdffee6/Lyspyw4cPd1dddZW79957XUNDg3VbCbdjxw4n6ayxcOFC59yZR7Gffvppl5mZ6Xw+n5s9e7arr6+3bToBznceTpw44YqKityVV17phg0b5saNG+cWL1484H5I6+nfL8mtXbs2csxnn33mHnnkEfe1r33NXX755e7OO+90LS0tdk0nwIXOQ1NTk5s5c6ZLS0tzPp/PTZgwwT3xxBMuFArZNv4V/DkGAICJPv8eEABgYCKAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGDi/wDGcP8WgexZhgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision.transforms import ToTensor, Resize\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "image_path = \"two.png\"\n",
    "image = Image.open(image_path)\n",
    "image = image.convert(\"L\")\n",
    "\n",
    "resize_transform = Resize((28, 28))\n",
    "image = resize_transform(image)\n",
    "\n",
    "transform = ToTensor()\n",
    "tensor_image = transform(image)\n",
    "\n",
    "inverted_tensor_image = 1 - tensor_image\n",
    "\n",
    "print(tensor_image.shape)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "data, target = test_data[120]\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "data = data.unsqueeze(0).to(device)\n",
    "\n",
    "output = model(data)\n",
    "print(output)\n",
    "prediction = output.argmax(dim = 1, keepdim=True).item()\n",
    "\n",
    "print(f'Prediction: {prediction}')\n",
    "\n",
    "image = data.squeeze(0).squeeze(0).cpu().numpy()\n",
    "\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b715f136-5671-47eb-9d66-23548501dfa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
